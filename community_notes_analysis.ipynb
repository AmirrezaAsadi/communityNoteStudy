{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Community Notes Study\n",
    "\n",
    "This notebook analyzes Community Notes data from the file `notes-00000-2.tsv`.\n",
    "\n",
    "Community Notes (formerly known as Birdwatch) is a collaborative system on X (Twitter) that allows users to add context to potentially misleading posts."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Setup and Data Loading\n",
    "\n",
    "First, let's import the necessary libraries and load the data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from pathlib import Path\n",
    "\n",
    "# Set visualization style\n",
    "sns.set_style('whitegrid')\n",
    "plt.rcParams['figure.figsize'] = (12, 6)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load the data\n",
    "data_file = 'notes-00000-2.tsv'\n",
    "\n",
    "# Check if file exists\n",
    "if not Path(data_file).exists():\n",
    "    print(f\"Warning: {data_file} not found. Please ensure the file is in the same directory as this notebook.\")\n",
    "else:\n",
    "    # Read the TSV file\n",
    "    df = pd.read_csv(data_file, sep='\\t')\n",
    "    print(f\"Successfully loaded {len(df)} rows from {data_file}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data Overview\n",
    "\n",
    "Let's examine the structure and contents of the dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Display basic information about the dataset\n",
    "print(\"Dataset Shape:\", df.shape)\n",
    "print(\"\\nColumn Names:\")\n",
    "print(df.columns.tolist())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Display first few rows\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Data types and missing values\n",
    "print(\"Data Types and Missing Values:\")\n",
    "info_df = pd.DataFrame({\n",
    "    'Data Type': df.dtypes,\n",
    "    'Non-Null Count': df.count(),\n",
    "    'Null Count': df.isnull().sum(),\n",
    "    'Null Percentage': (df.isnull().sum() / len(df) * 100).round(2)\n",
    "})\n",
    "display(info_df)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Descriptive Statistics\n",
    "\n",
    "Let's compute basic statistics for numerical columns."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Descriptive statistics for numerical columns\n",
    "df.describe()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data Analysis\n",
    "\n",
    "### Analysis by Classification\n",
    "\n",
    "If the data contains classification information, let's analyze the distribution."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Check for common Community Notes columns\n",
    "classification_cols = [col for col in df.columns if 'classification' in col.lower()]\n",
    "\n",
    "if classification_cols:\n",
    "    for col in classification_cols:\n",
    "        print(f\"\\nDistribution of {col}:\")\n",
    "        print(df[col].value_counts())\n",
    "        print(f\"\\nPercentage distribution:\")\n",
    "        print(df[col].value_counts(normalize=True) * 100)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Temporal Analysis\n",
    "\n",
    "If timestamp data is available, let's analyze trends over time."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Look for timestamp columns\n",
    "time_cols = [col for col in df.columns if any(x in col.lower() for x in ['time', 'date', 'created'])]\n",
    "\n",
    "if time_cols:\n",
    "    print(\"Time-related columns found:\")\n",
    "    for col in time_cols:\n",
    "        print(f\"- {col}\")\n",
    "        # Try to convert to datetime\n",
    "        try:\n",
    "            df[col + '_datetime'] = pd.to_datetime(df[col], unit='ms', errors='coerce')\n",
    "            print(f\"  Successfully converted to datetime\")\n",
    "        except:\n",
    "            print(f\"  Could not convert to datetime\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Visualizations\n",
    "\n",
    "Let's create some visualizations to better understand the data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Visualization 1: Distribution of classifications (if available)\n",
    "if classification_cols:\n",
    "    fig, axes = plt.subplots(1, len(classification_cols), figsize=(6*len(classification_cols), 6))\n",
    "    if len(classification_cols) == 1:\n",
    "        axes = [axes]\n",
    "    \n",
    "    for idx, col in enumerate(classification_cols):\n",
    "        df[col].value_counts().plot(kind='bar', ax=axes[idx])\n",
    "        axes[idx].set_title(f'Distribution of {col}')\n",
    "        axes[idx].set_xlabel(col)\n",
    "        axes[idx].set_ylabel('Count')\n",
    "        axes[idx].tick_params(axis='x', rotation=45)\n",
    "    \n",
    "    plt.tight_layout()\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Visualization 2: Missing data heatmap\n",
    "if len(df.columns) <= 50:  # Only if we have a reasonable number of columns\n",
    "    plt.figure(figsize=(12, 8))\n",
    "    sns.heatmap(df.isnull(), cbar=True, yticklabels=False, cmap='viridis')\n",
    "    plt.title('Missing Data Pattern')\n",
    "    plt.tight_layout()\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Visualization 3: Numerical columns distribution\n",
    "numerical_cols = df.select_dtypes(include=[np.number]).columns.tolist()\n",
    "\n",
    "if numerical_cols and len(numerical_cols) <= 10:\n",
    "    n_cols = min(3, len(numerical_cols))\n",
    "    n_rows = (len(numerical_cols) + n_cols - 1) // n_cols\n",
    "    \n",
    "    fig, axes = plt.subplots(n_rows, n_cols, figsize=(6*n_cols, 5*n_rows))\n",
    "    axes = axes.flatten() if len(numerical_cols) > 1 else [axes]\n",
    "    \n",
    "    for idx, col in enumerate(numerical_cols):\n",
    "        df[col].hist(bins=30, ax=axes[idx], edgecolor='black')\n",
    "        axes[idx].set_title(f'Distribution of {col}')\n",
    "        axes[idx].set_xlabel(col)\n",
    "        axes[idx].set_ylabel('Frequency')\n",
    "    \n",
    "    # Hide extra subplots\n",
    "    for idx in range(len(numerical_cols), len(axes)):\n",
    "        axes[idx].axis('off')\n",
    "    \n",
    "    plt.tight_layout()\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Text Analysis\n",
    "\n",
    "If the dataset contains text fields (like note summaries), let's analyze them."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Find text columns (object type with long strings)\n",
    "text_cols = []\n",
    "for col in df.select_dtypes(include=['object']).columns:\n",
    "    if df[col].notna().any():\n",
    "        avg_len = df[col].dropna().astype(str).str.len().mean()\n",
    "        if avg_len > 20:  # Likely a text field\n",
    "            text_cols.append(col)\n",
    "\n",
    "if text_cols:\n",
    "    print(\"Text columns found:\")\n",
    "    for col in text_cols:\n",
    "        print(f\"\\n{col}:\")\n",
    "        print(f\"  Average length: {df[col].dropna().astype(str).str.len().mean():.2f} characters\")\n",
    "        print(f\"  Sample: {df[col].dropna().iloc[0][:100]}...\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Word count distribution for text columns\n",
    "if text_cols:\n",
    "    for col in text_cols[:3]:  # Limit to first 3 text columns\n",
    "        word_counts = df[col].dropna().astype(str).str.split().str.len()\n",
    "        \n",
    "        plt.figure(figsize=(10, 5))\n",
    "        plt.hist(word_counts, bins=30, edgecolor='black')\n",
    "        plt.title(f'Word Count Distribution in {col}')\n",
    "        plt.xlabel('Number of Words')\n",
    "        plt.ylabel('Frequency')\n",
    "        plt.show()\n",
    "        \n",
    "        print(f\"\\nStatistics for {col}:\")\n",
    "        print(f\"  Mean word count: {word_counts.mean():.2f}\")\n",
    "        print(f\"  Median word count: {word_counts.median():.2f}\")\n",
    "        print(f\"  Max word count: {word_counts.max():.0f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Correlation Analysis\n",
    "\n",
    "Let's examine correlations between numerical variables."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Correlation matrix for numerical columns\n",
    "if len(numerical_cols) > 1:\n",
    "    correlation_matrix = df[numerical_cols].corr()\n",
    "    \n",
    "    plt.figure(figsize=(10, 8))\n",
    "    sns.heatmap(correlation_matrix, annot=True, fmt='.2f', cmap='coolwarm', \n",
    "                center=0, square=True, linewidths=1)\n",
    "    plt.title('Correlation Matrix of Numerical Features')\n",
    "    plt.tight_layout()\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Summary Statistics\n",
    "\n",
    "Let's create a comprehensive summary of the dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"=\"*60)\n",
    "print(\"COMMUNITY NOTES DATASET SUMMARY\")\n",
    "print(\"=\"*60)\n",
    "print(f\"\\nTotal number of notes: {len(df):,}\")\n",
    "print(f\"Number of features: {len(df.columns)}\")\n",
    "print(f\"\\nMemory usage: {df.memory_usage(deep=True).sum() / 1024**2:.2f} MB\")\n",
    "print(f\"\\nData completeness: {(1 - df.isnull().sum().sum() / (len(df) * len(df.columns))) * 100:.2f}%\")\n",
    "\n",
    "if classification_cols:\n",
    "    print(f\"\\nClassification columns: {', '.join(classification_cols)}\")\n",
    "\n",
    "if text_cols:\n",
    "    print(f\"\\nText columns: {', '.join(text_cols)}\")\n",
    "\n",
    "print(f\"\\nNumerical columns: {len(numerical_cols)}\")\n",
    "print(f\"Categorical columns: {len(df.select_dtypes(include=['object']).columns)}\")\n",
    "print(\"=\"*60)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Key Insights\n",
    "\n",
    "Based on the analysis above, here are some key observations:\n",
    "\n",
    "1. **Data Volume**: The dataset contains community notes that can be analyzed for patterns and trends.\n",
    "2. **Data Quality**: Check the missing data patterns to understand data completeness.\n",
    "3. **Classifications**: If present, classification distributions show how notes are categorized.\n",
    "4. **Text Content**: Text analysis reveals the nature and length of note contents.\n",
    "\n",
    "### Next Steps\n",
    "\n",
    "Further analysis could include:\n",
    "- Sentiment analysis on text fields\n",
    "- Topic modeling to identify common themes\n",
    "- Time series analysis if temporal data is available\n",
    "- Network analysis of note relationships\n",
    "- Comparison with rating data if available"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Export Results\n",
    "\n",
    "Optionally, save processed data or summary statistics."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Example: Save summary statistics to CSV\n",
    "# summary = df.describe(include='all')\n",
    "# summary.to_csv('community_notes_summary.csv')\n",
    "# print(\"Summary statistics saved to community_notes_summary.csv\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}